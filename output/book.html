<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Yuan Wang" />
  <meta name="dcterms.date" content="2025-01-01" />
  <title>GPU Programming using CUDA and C++</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      font-size: 11pt;
      line-height: 1.2;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: blue;
    }
    a:visited {
      color: blue;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<header id="title-block-header">
<h1 class="title">GPU Programming using CUDA and C++</h1>
<p class="author">Yuan Wang</p>
<p class="date">2025</p>
</header>
<nav id="TOC" role="doc-toc">

</nav>
<p>Unlike the conventional CPU-based architecture, where CPU cores are
much more limited, GPU has many more cores, even in consumer products. A
comparison of CPU and GPU architecture is illustrated in Fig.~<span
class="math inline">\(\ref{cpu_gpu_comparison}\)</span>. The
terminologies “core” for both CPU and GPU mentioned earlier, though,
have different implications. For instance, dual physical cores in an
INTEL CPU can have up to four virtual threads, known as hyperthreading,
and each physical core consists of an arithmetic logic unit (ALU), a
logic control unit, and caches, while the NVIDIA CUDA core usually
refers to a large number of execution units following the concept of
“Single Instruction, Multiple Data” (SIMD)~. Thanks to the SIMD feature,
CUDA is used for the first time for deep convolutional neural networks,
known as AlexNet, in image identification in 2012~.</p>
<p>Generally speaking, each thread of a CPU comes with an execution of a
task at a fast speed, but is limited by the number of threads running
concurrently; however, there are thousands of threads running in
parallel in GPU but with a slower execution speed per thread. There are
always advantages and disadvantages when choosing the preferable
architecture for executing certain tasks.</p>
<p>Figure~<span class="math inline">\(\ref{cpu_gpu_comparison}\)</span>
depicts the main difference between a CPU and a GPU in that unlike a CPU
where each core has its control unit and can access the CPU’s fast
memory (cache), in a GPU, cores are organized into groups, with each
group controlled by a single control unit and sharing access to a cache.
Both the CPU and the GPU are connected to dynamic random-access memory
(DRAM); the CPU directly accesses the system’s DRAM, while the Nvidia
GPU, designed for CUDA, operates using its dedicated memory, often
referred to as GPU global memory, a specific variant of DRAM, to handle
its computations.</p>
<p>Before attempting to go into detail, keep in mind that parallel
computing is not confined to a particular type of hardware, such as a
GPU. Instead, it is a concept that applies to any hardware capable of
concurrent operations, including multicore CPUs, which can also perform
parallel processing up to a certain extent. In other words, parallel
programming is fundamentally about algorithm design rather than the
specifics of the underlying hardware. For instance, in a parallel
computing network, various units can be interconnected, and each unit
can comprise different elements, such as CPUs, GPUs, Field Programmable
Gate Arrays (FPGAs), or other computational units.</p>
</body>
</html>
